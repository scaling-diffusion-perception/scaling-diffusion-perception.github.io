<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Scaling Diffusion Perception</title>
    <link rel="stylesheet" href="style.css">
</head>
<body>

    <!-- Title Section -->
    <div id="title_slide">
        <div class="title_center">
            <h1>Scaling Properties of Diffusion Models For Perceptual Tasks</h1>
        </div>
    </div>

    <!-- Author Section -->
    <div class="author-container-1">
        <div class="grid-item"><a href="">Rahul Ravishankar*</a></div>
        <div class="grid-item"><a href="https://zeeshanp.me">Zeeshan Patel*</a></div>
        <div class="grid-item"><a href="https://brjathu.github.io">Jathushan Rajasegaran</a></div>
        <div class="grid-item"><a href="https://people.eecs.berkeley.edu/~malik/">Jitendra Malik</a></div>
    </div>    

    <!-- Affiliation Section -->
    <div class="berkeley">
        <p>University of California, Berkeley</p>
    </div>
    <div class="equal_contribution">
        <p>*Equal Contribution</p>
    </div>

    <div class="button-container">
        <a href="#" class="button">Paper</a>
        <a href="https://github.com/scaling-diffusion-perception/scaling-diffusion-perception" class="button">Code</a>
    </div>

    <!-- Abstract Section -->
    <div id="abstract">
        <p>
            In this paper, we argue that iterative computation with diffusion models offers a powerful paradigm for not only generation but also visual perception tasks. We unify tasks such as depth estimation, optical flow, and segmentation under image-to-image translation, and show how diffusion models benefit from scaling training and test-time compute for these perception tasks. Through a careful analysis of these scaling behaviors, we present various techniques to efficiently train diffusion models for visual perception tasks. Our models achieve improved or comparable performance to state-of-the-art methods using significantly less data and compute.
        </p>
    </div>

    <!-- Divider Line -->
    <br />
    <hr class="rounded">

    <!-- Overview Section -->
    <div id="overview">
        <h1>Scaling Diffusion Models For Perceptual Tasks</h1>
        <p>
            We display the effectiveness of leveraging iterative feedback computation through diffusion models for visual perception tasks. We perform an in-depth study of train/test-time compute scaling laws across all layers
            of the stack, including pre-training, fine-tuning, and diffusion inference. Specifically, we perform our study on the monocular depth estimation task. We show how to transfer the scaling laws derived for depth estimation to boost performance
            on tasks such as optical flow or amodal segmentation for both training and inference. Finally, we apply all of our scaling strategies to efficiently train a generalist mixture-of-experts model on perception tasks, achieving state-of-the-art results across various benchmarks.
        </p>
        <!-- Image Container -->
        <div class="image_container">
            <img src="assets/method.png" alt="Scaling Diffusion Method" class="overview_image">
            <div class="caption", style="text-align: justify;">
                <p> Figure 1: <b>A Unified Framework</b>: We fine-tune a pre-trained Diffusion Model (DM) for visual
                    perception tasks. We take a RGB image, and a conditional image (i.e. next video frame, occlusion
                    mask, etc.), along with the noised image of the ground truth prediction. Our model generates pre-
                    dictions for various visual tasks such as monocular depth estimation, optical flow prediction, and
                    amodal segmentation / completion, based on the conditional task embedding. We train a general-
                    ist model that can perform all three tasks with exceptional performance.</p>
            </div>
        </div>
    </div>

    <!-- Divider Line -->
    <br />
    <hr class="rounded">

    <!-- <div id="overview">
        <h1>Scaling Diffusion Training</h1>
        <p>
        </p>
    </div> -->

    <br />
    <br />
    <br />
    <br />

   
</body>
</html>